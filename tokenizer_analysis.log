`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.
Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.
Loading model...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.48s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.63s/it]
You are not running the flash-attention implementation, expect numerical differences.
`torch_dtype` is deprecated! Use `dtype` instead!
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Model loaded. Generating response...

tensor([[  806,  1446,  7513, 29915, 29879,  8158,  1492,  1286, 29973,    13,
            13,  1451,   271,  7451, 29901,   306, 29915, 29885,  7423, 29892,
           541,   306, 29915, 29885,  9368,   304,  3867,  1855, 29899,  2230,
         14717, 19435,   470,  5735, 11217, 29889,  1152,   278,  9281,  2472,
           373,  2181,  8522, 19435, 29892,  3113,  1423,   263, 23279, 14717,
          9763,  4700,   470,   263, 14717,  9763,   623, 29889,    13]],
       device='mps:0')
Wh
ats
India
'
s
score
right
now
?
-------------------
-------------------
-------------------
-------------------
-------------------
</s>

Sub
jedoch
Whats India's score right now?

Chatbot: I'm sorry, but I'm unable to provide real-time sports scores or live updates. For the latest information on cricket scores, please check a reliable sports news website or a sports news app.


âœ“ Generation complete with KV cache enabled!


============================================================
FLAN-T5 (2022) - Encoder-Decoder Seq2Seq Model
============================================================

Loading Flan-T5 model...
Model: google/flan-t5-base
Note: Flan-T5 is a Seq2Seq model optimized for instruction-following tasks

Flan-T5 loaded. Generating response...

Prompt: Translate to French: How are you today?

Generated Response: Comment vous Ãªtes aujourd'hui?

Full output (with special tokens): <pad> Comment vous Ãªtes aujourd'hui?</s>
Token IDs: [0, 5257, 327, 3, 6738, 7082, 31, 3464, 58, 1]

------------------------------------------------------------
Flan-T5 Special Tokens:
------------------------------------------------------------
  PAD token: '<pad>' (ID: 0)
  EOS token: '</s>' (ID: 1)
  UNK token: '<unk>' (ID: 2)

Note: T5/Flan-T5 uses a different architecture than BERT:
  - Uses EOS (</s>) instead of SEP
  - Uses PAD (<pad>) for padding
  - NO CLS token (encoder-decoder, not classification-focused)
  - NO MASK token (uses span corruption during pretraining)

âœ“ Flan-T5 generation complete!


================================================================================
COMPREHENSIVE TOKENIZER COMPARISON & ANALYSIS
================================================================================


ğŸ“‹ Test text overview:
--------------------------------------------------------------------------------
English and CAPITALIZATION
show_tokens False None elif == >= else: two tabs:"		" Three tabs:			
12.0*50=600
ğŸ«¡ğŸ‘‹ğŸ¾ğŸ¤—ğŸ¥´ğŸ˜¶â€ğŸŒ«ï¸
ÛÙ†Ø¯ÛŒä¸­æ–‡Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©í•œêµ­ì–´
--------------------------------------------------------------------------------

Total characters: 134
Contains: English, capitalization, Python code, operators, numbers,
          emojis, non-English scripts (Urdu, Hindi, Chinese, Arabic, Korean)

================================================================================
ğŸ“Š BERT base model (uncased)
================================================================================

ğŸ“ˆ BASIC STATISTICS:
  â€¢ Total tokens: 59
  â€¢ Original text length: 134 characters
  â€¢ Compression ratio: 2.27 chars/token
  â€¢ Vocabulary size: 30,522

ğŸ”– SPECIAL TOKENS:
  â€¢ PAD: '[PAD]' (ID: 0)
  â€¢ UNK: '[UNK]' (ID: 100)
  â€¢ CLS: '[CLS]' (ID: 101)
  â€¢ SEP: '[SEP]' (ID: 102)
  â€¢ MASK: '[MASK]' (ID: 103)

ğŸ”§ TOKENIZATION STRATEGY:
  â€¢ Tokenizer class: BertTokenizerFast
  â€¢ Strategy: WordPiece (BERT-style)
  â€¢ Model max length: 512

ğŸ“Š TOKEN BREAKDOWN ANALYSIS:
  â€¢ Special tokens in output: 3
  â€¢ Unknown tokens [UNK]: 1
  â€¢ Subword tokens: 22
  â€¢ Regular tokens: 34

ğŸ” CONTENT-SPECIFIC HANDLING:
  â€¢ Capitalization: 2 tokens (avg 7.00 chars/token)
  â€¢ Python keywords: 4 tokens (avg 3.75 chars/token)
  â€¢ Operators: 4 tokens (avg 1.25 chars/token)
  â€¢ Numbers: 7 tokens (avg 1.57 chars/token)
  â€¢ Emojis: 1 tokens (avg 4.00 chars/token)
  â€¢ Non-English: 21 tokens (avg 0.76 chars/token)

ğŸ¨ VISUAL TOKENIZATION:
  [0;30;48;2;102;194;165m[CLS][0m [0;30;48;2;252;141;98menglish[0m [0;30;48;2;141;160;203mand[0m [0;30;48;2;231;138;195mcapital[0m [0;30;48;2;166;216;84m##ization[0m [0;30;48;2;255;217;47mshow[0m [0;30;48;2;255;127;0m_[0m [0;30;48;2;202;178;214mtoken[0m [0;30;48;2;106;61;154m##s[0m [0;30;48;2;102;194;165mfalse[0m [0;30;48;2;252;141;98mnone[0m [0;30;48;2;141;160;203meli[0m [0;30;48;2;231;138;195m##f[0m [0;30;48;2;166;216;84m=[0m [0;30;48;2;255;217;47m=[0m [0;30;48;2;255;127;0m>[0m [0;30;48;2;202;178;214m=[0m [0;30;48;2;106;61;154melse[0m [0;30;48;2;102;194;165m:[0m [0;30;48;2;252;141;98mtwo[0m [0;30;48;2;141;160;203mtab[0m [0;30;48;2;231;138;195m##s[0m [0;30;48;2;166;216;84m:[0m [0;30;48;2;255;217;47m"[0m [0;30;48;2;255;127;0m"[0m [0;30;48;2;202;178;214mthree[0m [0;30;48;2;106;61;154mtab[0m [0;30;48;2;102;194;165m##s[0m [0;30;48;2;252;141;98m:[0m [0;30;48;2;141;160;203m12[0m [0;30;48;2;231;138;195m.[0m [0;30;48;2;166;216;84m0[0m [0;30;48;2;255;217;47m*[0m [0;30;48;2;255;127;0m50[0m [0;30;48;2;202;178;214m=[0m [0;30;48;2;106;61;154m600[0m [0;30;48;2;102;194;165m[UNK][0m [0;30;48;2;252;141;98mÛ[0m [0;30;48;2;141;160;203m##Ù†[0m [0;30;48;2;231;138;195m##Ø¯[0m [0;30;48;2;166;216;84m##ÛŒ[0m [0;30;48;2;255;217;47mä¸­[0m [0;30;48;2;255;127;0mæ–‡[0m [0;30;48;2;202;178;214mØ§[0m [0;30;48;2;106;61;154m##Ù„[0m [0;30;48;2;102;194;165m##Ø¹[0m [0;30;48;2;252;141;98m##Ø±[0m [0;30;48;2;141;160;203m##Ø¨[0m [0;30;48;2;231;138;195m##ÙŠ[0m [0;30;48;2;166;216;84m##Ø©[0m [0;30;48;2;255;217;47m##á„’[0m [0;30;48;2;255;127;0m##á…¡[0m [0;30;48;2;202;178;214m##á†«[0m [0;30;48;2;106;61;154m##á„€[0m [0;30;48;2;102;194;165m##á…®[0m [0;30;48;2;252;141;98m##á†¨[0m [0;30;48;2;141;160;203m##á„‹[0m [0;30;48;2;231;138;195m##á…¥[0m [0;30;48;2;166;216;84m[SEP][0m 

ğŸ“ DETAILED TOKEN LIST (first 50 tokens):
  [ 0] ID:   101 â†’ [CLS]
  [ 1] ID:  2394 â†’ english
  [ 2] ID:  1998 â†’ and
  [ 3] ID:  3007 â†’ capital
  [ 4] ID:  3989 â†’ ##ization
  [ 5] ID:  2265 â†’ show
  [ 6] ID:  1035 â†’ _
  [ 7] ID: 19204 â†’ token
  [ 8] ID:  2015 â†’ ##s
  [ 9] ID:  6270 â†’ false
  [10] ID:  3904 â†’ none
  [11] ID: 12005 â†’ eli
  [12] ID:  2546 â†’ ##f
  [13] ID:  1027 â†’ =
  [14] ID:  1027 â†’ =
  [15] ID:  1028 â†’ >
  [16] ID:  1027 â†’ =
  [17] ID:  2842 â†’ else
  [18] ID:  1024 â†’ :
  [19] ID:  2048 â†’ two
  [20] ID: 21628 â†’ tab
  [21] ID:  2015 â†’ ##s
  [22] ID:  1024 â†’ :
  [23] ID:  1000 â†’ "
  [24] ID:  1000 â†’ "
  [25] ID:  2093 â†’ three
  [26] ID: 21628 â†’ tab
  [27] ID:  2015 â†’ ##s
  [28] ID:  1024 â†’ :
  [29] ID:  2260 â†’ 12
  [30] ID:  1012 â†’ .
  [31] ID:  1014 â†’ 0
  [32] ID:  1008 â†’ *
  [33] ID:  2753 â†’ 50
  [34] ID:  1027 â†’ =
  [35] ID:  5174 â†’ 600
  [36] ID:   100 â†’ [UNK]
  [37] ID:  1308 â†’ Û
  [38] ID: 15915 â†’ ##Ù†
  [39] ID: 15394 â†’ ##Ø¯
  [40] ID: 24830 â†’ ##ÛŒ
  [41] ID:  1746 â†’ ä¸­
  [42] ID:  1861 â†’ æ–‡
  [43] ID:  1270 â†’ Ø§
  [44] ID: 23673 â†’ ##Ù„
  [45] ID: 29830 â†’ ##Ø¹
  [46] ID: 17149 â†’ ##Ø±
  [47] ID: 29816 â†’ ##Ø¨
  [48] ID: 14498 â†’ ##ÙŠ
  [49] ID: 19433 â†’ ##Ø©
  ... and 9 more tokens

================================================================================
ğŸ“Š BERT base model (cased)
================================================================================

ğŸ“ˆ BASIC STATISTICS:
  â€¢ Total tokens: 53
  â€¢ Original text length: 134 characters
  â€¢ Compression ratio: 2.53 chars/token
  â€¢ Vocabulary size: 28,996

ğŸ”– SPECIAL TOKENS:
  â€¢ PAD: '[PAD]' (ID: 0)
  â€¢ UNK: '[UNK]' (ID: 100)
  â€¢ CLS: '[CLS]' (ID: 101)
  â€¢ SEP: '[SEP]' (ID: 102)
  â€¢ MASK: '[MASK]' (ID: 103)

ğŸ”§ TOKENIZATION STRATEGY:
  â€¢ Tokenizer class: BertTokenizerFast
  â€¢ Strategy: WordPiece (BERT-style)
  â€¢ Model max length: 512

ğŸ“Š TOKEN BREAKDOWN ANALYSIS:
  â€¢ Special tokens in output: 4
  â€¢ Unknown tokens [UNK]: 2
  â€¢ Subword tokens: 16
  â€¢ Regular tokens: 33

ğŸ” CONTENT-SPECIFIC HANDLING:
  â€¢ Capitalization: 8 tokens (avg 1.75 chars/token)
  â€¢ Python keywords: 6 tokens (avg 2.50 chars/token)
  â€¢ Operators: 4 tokens (avg 1.25 chars/token)
  â€¢ Numbers: 7 tokens (avg 1.57 chars/token)
  â€¢ Emojis: 1 tokens (avg 4.00 chars/token)
  â€¢ Non-English: 7 tokens (avg 2.29 chars/token)

ğŸ¨ VISUAL TOKENIZATION:
  [0;30;48;2;102;194;165m[CLS][0m [0;30;48;2;252;141;98mEnglish[0m [0;30;48;2;141;160;203mand[0m [0;30;48;2;231;138;195mCA[0m [0;30;48;2;166;216;84m##PI[0m [0;30;48;2;255;217;47m##TA[0m [0;30;48;2;255;127;0m##L[0m [0;30;48;2;202;178;214m##I[0m [0;30;48;2;106;61;154m##Z[0m [0;30;48;2;102;194;165m##AT[0m [0;30;48;2;252;141;98m##ION[0m [0;30;48;2;141;160;203mshow[0m [0;30;48;2;231;138;195m_[0m [0;30;48;2;166;216;84mtoken[0m [0;30;48;2;255;217;47m##s[0m [0;30;48;2;255;127;0mF[0m [0;30;48;2;202;178;214m##als[0m [0;30;48;2;106;61;154m##e[0m [0;30;48;2;102;194;165mNone[0m [0;30;48;2;252;141;98mel[0m [0;30;48;2;141;160;203m##if[0m [0;30;48;2;231;138;195m=[0m [0;30;48;2;166;216;84m=[0m [0;30;48;2;255;217;47m>[0m [0;30;48;2;255;127;0m=[0m [0;30;48;2;202;178;214melse[0m [0;30;48;2;106;61;154m:[0m [0;30;48;2;102;194;165mtwo[0m [0;30;48;2;252;141;98mta[0m [0;30;48;2;141;160;203m##bs[0m [0;30;48;2;231;138;195m:[0m [0;30;48;2;166;216;84m"[0m [0;30;48;2;255;217;47m"[0m [0;30;48;2;255;127;0mThree[0m [0;30;48;2;202;178;214mta[0m [0;30;48;2;106;61;154m##bs[0m [0;30;48;2;102;194;165m:[0m [0;30;48;2;252;141;98m12[0m [0;30;48;2;141;160;203m.[0m [0;30;48;2;231;138;195m0[0m [0;30;48;2;166;216;84m*[0m [0;30;48;2;255;217;47m50[0m [0;30;48;2;255;127;0m=[0m [0;30;48;2;202;178;214m600[0m [0;30;48;2;106;61;154m[UNK][0m [0;30;48;2;102;194;165mÛ[0m [0;30;48;2;252;141;98m##Ù†[0m [0;30;48;2;141;160;203m##Ø¯[0m [0;30;48;2;231;138;195m##ÛŒ[0m [0;30;48;2;166;216;84mä¸­[0m [0;30;48;2;255;217;47mæ–‡[0m [0;30;48;2;255;127;0m[UNK][0m [0;30;48;2;202;178;214m[SEP][0m 

ğŸ“ DETAILED TOKEN LIST (first 50 tokens):
  [ 0] ID:   101 â†’ [CLS]
  [ 1] ID:  1483 â†’ English
  [ 2] ID:  1105 â†’ and
  [ 3] ID:  8784 â†’ CA
  [ 4] ID: 23203 â†’ ##PI
  [ 5] ID:  9159 â†’ ##TA
  [ 6] ID:  2162 â†’ ##L
  [ 7] ID:  2240 â†’ ##I
  [ 8] ID:  5301 â†’ ##Z
  [ 9] ID: 13821 â†’ ##AT
  [10] ID: 24805 â†’ ##ION
  [11] ID:  1437 â†’ show
  [12] ID:   168 â†’ _
  [13] ID: 22559 â†’ token
  [14] ID:  1116 â†’ ##s
  [15] ID:   143 â†’ F
  [16] ID:  7264 â†’ ##als
  [17] ID:  1162 â†’ ##e
  [18] ID:  7330 â†’ None
  [19] ID:  8468 â†’ el
  [20] ID:  8914 â†’ ##if
  [21] ID:   134 â†’ =
  [22] ID:   134 â†’ =
  [23] ID:   135 â†’ >
  [24] ID:   134 â†’ =
  [25] ID:  1950 â†’ else
  [26] ID:   131 â†’ :
  [27] ID:  1160 â†’ two
  [28] ID: 27629 â†’ ta
  [29] ID:  4832 â†’ ##bs
  [30] ID:   131 â†’ :
  [31] ID:   107 â†’ "
  [32] ID:   107 â†’ "
  [33] ID:  2677 â†’ Three
  [34] ID: 27629 â†’ ta
  [35] ID:  4832 â†’ ##bs
  [36] ID:   131 â†’ :
  [37] ID:  1367 â†’ 12
  [38] ID:   119 â†’ .
  [39] ID:   121 â†’ 0
  [40] ID:   115 â†’ *
  [41] ID:  1851 â†’ 50
  [42] ID:   134 â†’ =
  [43] ID:  4372 â†’ 600
  [44] ID:   100 â†’ [UNK]
  [45] ID:   602 â†’ Û
  [46] ID: 17754 â†’ ##Ù†
  [47] ID: 18191 â†’ ##Ø¯
  [48] ID: 28506 â†’ ##ÛŒ
  [49] ID:   980 â†’ ä¸­
  ... and 3 more tokens

================================================================================
ğŸ“Š GPT-2
================================================================================

ğŸ“ˆ BASIC STATISTICS:
  â€¢ Total tokens: 87
  â€¢ Original text length: 134 characters
  â€¢ Compression ratio: 1.54 chars/token
  â€¢ Vocabulary size: 50,257

ğŸ”– SPECIAL TOKENS:
  â€¢ UNK: '<|endoftext|>' (ID: 50256)
  â€¢ BOS: '<|endoftext|>' (ID: 50256)
  â€¢ EOS: '<|endoftext|>' (ID: 50256)

ğŸ”§ TOKENIZATION STRATEGY:
  â€¢ Tokenizer class: GPT2TokenizerFast
  â€¢ Strategy: Byte-Pair Encoding (BPE)
  â€¢ Model max length: 1024

ğŸ“Š TOKEN BREAKDOWN ANALYSIS:
  â€¢ Special tokens in output: 0
  â€¢ Unknown tokens [UNK]: 0
  â€¢ Subword tokens: 0
  â€¢ Regular tokens: 87

ğŸ” CONTENT-SPECIFIC HANDLING:
  â€¢ Capitalization: 4 tokens (avg 3.50 chars/token)
  â€¢ Python keywords: 4 tokens (avg 3.75 chars/token)
  â€¢ Operators: 2 tokens (avg 2.50 chars/token)
  â€¢ Numbers: 7 tokens (avg 1.57 chars/token)
  â€¢ Emojis: 11 tokens (avg 0.36 chars/token)
  â€¢ Non-English: 23 tokens (avg 0.70 chars/token)

ğŸ¨ VISUAL TOKENIZATION:
  [0;30;48;2;102;194;165mEnglish[0m [0;30;48;2;252;141;98mÂ·and[0m [0;30;48;2;141;160;203mÂ·CAP[0m [0;30;48;2;231;138;195mITAL[0m [0;30;48;2;166;216;84mIZ[0m [0;30;48;2;255;217;47mATION[0m [0;30;48;2;255;127;0m\n[0m [0;30;48;2;202;178;214mshow[0m [0;30;48;2;106;61;154m_[0m [0;30;48;2;102;194;165mt[0m [0;30;48;2;252;141;98mok[0m [0;30;48;2;141;160;203mens[0m [0;30;48;2;231;138;195mÂ·False[0m [0;30;48;2;166;216;84mÂ·None[0m [0;30;48;2;255;217;47mÂ·el[0m [0;30;48;2;255;127;0mif[0m [0;30;48;2;202;178;214mÂ·==[0m [0;30;48;2;106;61;154mÂ·>=[0m [0;30;48;2;102;194;165mÂ·else[0m [0;30;48;2;252;141;98m:[0m [0;30;48;2;141;160;203mÂ·two[0m [0;30;48;2;231;138;195mÂ·tabs[0m [0;30;48;2;166;216;84m:"[0m [0;30;48;2;255;217;47m\t[0m [0;30;48;2;255;127;0m\t[0m [0;30;48;2;202;178;214m"[0m [0;30;48;2;106;61;154mÂ·Three[0m [0;30;48;2;102;194;165mÂ·tabs[0m [0;30;48;2;252;141;98m:[0m [0;30;48;2;141;160;203m\t[0m [0;30;48;2;231;138;195m\t[0m [0;30;48;2;166;216;84m\t[0m [0;30;48;2;255;217;47m\n[0m [0;30;48;2;255;127;0m12[0m [0;30;48;2;202;178;214m.[0m [0;30;48;2;106;61;154m0[0m [0;30;48;2;102;194;165m*[0m [0;30;48;2;252;141;98m50[0m [0;30;48;2;141;160;203m=[0m [0;30;48;2;231;138;195m600[0m [0;30;48;2;166;216;84m\n[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¸[0m [0;30;48;2;102;194;165m\n[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mÙ†[0m [0;30;48;2;166;216;84mØ¯[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mä¸­[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mØ§Ù„[0m [0;30;48;2;141;160;203mØ¹[0m [0;30;48;2;231;138;195mØ±[0m [0;30;48;2;166;216;84mØ¨[0m [0;30;48;2;255;217;47mÙŠ[0m [0;30;48;2;255;127;0mØ©[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m 

ğŸ“ DETAILED TOKEN LIST (first 50 tokens):
  [ 0] ID: 15823 â†’ English
  [ 1] ID:   290 â†’  and
  [ 2] ID: 20176 â†’  CAP
  [ 3] ID: 40579 â†’ ITAL
  [ 4] ID: 14887 â†’ IZ
  [ 5] ID:  6234 â†’ ATION
  [ 6] ID:   198 â†’ \n
  [ 7] ID: 12860 â†’ show
  [ 8] ID:    62 â†’ _
  [ 9] ID:    83 â†’ t
  [10] ID:   482 â†’ ok
  [11] ID:   641 â†’ ens
  [12] ID: 10352 â†’  False
  [13] ID:  6045 â†’  None
  [14] ID:  1288 â†’  el
  [15] ID:   361 â†’ if
  [16] ID:  6624 â†’  ==
  [17] ID: 18189 â†’  >=
  [18] ID:  2073 â†’  else
  [19] ID:    25 â†’ :
  [20] ID:   734 â†’  two
  [21] ID: 22524 â†’  tabs
  [22] ID: 11097 â†’ :"
  [23] ID:   197 â†’ \t
  [24] ID:   197 â†’ \t
  [25] ID:     1 â†’ "
  [26] ID:  7683 â†’  Three
  [27] ID: 22524 â†’  tabs
  [28] ID:    25 â†’ :
  [29] ID:   197 â†’ \t
  [30] ID:   197 â†’ \t
  [31] ID:   197 â†’ \t
  [32] ID:   198 â†’ \n
  [33] ID:  1065 â†’ 12
  [34] ID:    13 â†’ .
  [35] ID:    15 â†’ 0
  [36] ID:     9 â†’ *
  [37] ID:  1120 â†’ 50
  [38] ID:    28 â†’ =
  [39] ID:  8054 â†’ 600
  [40] ID:   198 â†’ \n
  [41] ID:  8582 â†’ ï¿½
  [42] ID:   104 â†’ ï¿½
  [43] ID:    94 â†’ ï¿½
  [44] ID: 41840 â†’ ï¿½
  [45] ID:   233 â†’ ï¿½
  [46] ID:  8582 â†’ ï¿½
  [47] ID:   237 â†’ ï¿½
  [48] ID:   122 â†’ ï¿½
  [49] ID:  8582 â†’ ï¿½
  ... and 37 more tokens

================================================================================
ğŸ“Š FLAN-T5
================================================================================

ğŸ“ˆ BASIC STATISTICS:
  â€¢ Total tokens: 49
  â€¢ Original text length: 134 characters
  â€¢ Compression ratio: 2.73 chars/token
  â€¢ Vocabulary size: 32,100

ğŸ”– SPECIAL TOKENS:
  â€¢ PAD: '<pad>' (ID: 0)
  â€¢ UNK: '<unk>' (ID: 2)
  â€¢ EOS: '</s>' (ID: 1)

ğŸ”§ TOKENIZATION STRATEGY:
  â€¢ Tokenizer class: T5TokenizerFast
  â€¢ Strategy: SentencePiece (Unigram)
  â€¢ Model max length: 512

ğŸ“Š TOKEN BREAKDOWN ANALYSIS:
  â€¢ Special tokens in output: 4
  â€¢ Unknown tokens [UNK]: 3
  â€¢ Subword tokens: 0
  â€¢ Regular tokens: 45

ğŸ” CONTENT-SPECIFIC HANDLING:
  â€¢ Capitalization: 5 tokens (avg 2.80 chars/token)
  â€¢ Python keywords: 8 tokens (avg 1.88 chars/token)
  â€¢ Operators: 4 tokens (avg 1.25 chars/token)
  â€¢ Numbers: 6 tokens (avg 1.83 chars/token)
  â€¢ Emojis: 2 tokens (avg 2.00 chars/token)
  â€¢ Non-English: 2 tokens (avg 8.00 chars/token)

ğŸ¨ VISUAL TOKENIZATION:
  [0;30;48;2;102;194;165mEnglish[0m [0;30;48;2;252;141;98mand[0m [0;30;48;2;141;160;203mCA[0m [0;30;48;2;231;138;195mPI[0m [0;30;48;2;166;216;84mTAL[0m [0;30;48;2;255;217;47mIZ[0m [0;30;48;2;255;127;0mATION[0m [0;30;48;2;202;178;214mshow[0m [0;30;48;2;106;61;154m_[0m [0;30;48;2;102;194;165mto[0m [0;30;48;2;252;141;98mken[0m [0;30;48;2;141;160;203ms[0m [0;30;48;2;231;138;195mFal[0m [0;30;48;2;166;216;84ms[0m [0;30;48;2;255;217;47me[0m [0;30;48;2;255;127;0mNone[0m [0;30;48;2;202;178;214mÂ·[0m [0;30;48;2;106;61;154me[0m [0;30;48;2;102;194;165ml[0m [0;30;48;2;252;141;98mif[0m [0;30;48;2;141;160;203m=[0m [0;30;48;2;231;138;195m=[0m [0;30;48;2;166;216;84m>[0m [0;30;48;2;255;217;47m=[0m [0;30;48;2;255;127;0melse[0m [0;30;48;2;202;178;214m:[0m [0;30;48;2;106;61;154mtwo[0m [0;30;48;2;102;194;165mtab[0m [0;30;48;2;252;141;98ms[0m [0;30;48;2;141;160;203m:[0m [0;30;48;2;231;138;195m"[0m [0;30;48;2;166;216;84m"[0m [0;30;48;2;255;217;47mThree[0m [0;30;48;2;255;127;0mtab[0m [0;30;48;2;202;178;214ms[0m [0;30;48;2;106;61;154m:[0m [0;30;48;2;102;194;165m12.[0m [0;30;48;2;252;141;98m0[0m [0;30;48;2;141;160;203m*[0m [0;30;48;2;231;138;195m50[0m [0;30;48;2;166;216;84m=[0m [0;30;48;2;255;217;47m600[0m [0;30;48;2;255;127;0mÂ·[0m [0;30;48;2;202;178;214m<unk>[0m [0;30;48;2;106;61;154mÂ·[0m [0;30;48;2;102;194;165m<unk>[0m [0;30;48;2;252;141;98mÂ·[0m [0;30;48;2;141;160;203m<unk>[0m [0;30;48;2;231;138;195m</s>[0m 

ğŸ“ DETAILED TOKEN LIST (first 50 tokens):
  [ 0] ID:  1566 â†’ English
  [ 1] ID:    11 â†’ and
  [ 2] ID:  3087 â†’ CA
  [ 3] ID:  4111 â†’ PI
  [ 4] ID: 16359 â†’ TAL
  [ 5] ID: 20091 â†’ IZ
  [ 6] ID:  8015 â†’ ATION
  [ 7] ID:   504 â†’ show
  [ 8] ID:   834 â†’ _
  [ 9] ID:   235 â†’ to
  [10] ID:  2217 â†’ ken
  [11] ID:     7 â†’ s
  [12] ID: 10747 â†’ Fal
  [13] ID:     7 â†’ s
  [14] ID:    15 â†’ e
  [15] ID: 14794 â†’ None
  [16] ID:     3 â†’ 
  [17] ID:    15 â†’ e
  [18] ID:    40 â†’ l
  [19] ID:    99 â†’ if
  [20] ID:  3274 â†’ =
  [21] ID:  2423 â†’ =
  [22] ID:  2490 â†’ >
  [23] ID:  2423 â†’ =
  [24] ID:  1307 â†’ else
  [25] ID:    10 â†’ :
  [26] ID:   192 â†’ two
  [27] ID:  3808 â†’ tab
  [28] ID:     7 â†’ s
  [29] ID:    10 â†’ :
  [30] ID:   121 â†’ "
  [31] ID:    96 â†’ "
  [32] ID:  5245 â†’ Three
  [33] ID:  3808 â†’ tab
  [34] ID:     7 â†’ s
  [35] ID:    10 â†’ :
  [36] ID:  8013 â†’ 12.
  [37] ID:   632 â†’ 0
  [38] ID:  1935 â†’ *
  [39] ID:  1752 â†’ 50
  [40] ID:  2423 â†’ =
  [41] ID:  6007 â†’ 600
  [42] ID:     3 â†’ 
  [43] ID:     2 â†’ <unk>
  [44] ID:     3 â†’ 
  [45] ID:     2 â†’ <unk>
  [46] ID:     3 â†’ 
  [47] ID:     2 â†’ <unk>
  [48] ID:     1 â†’ </s>

================================================================================
ğŸ“Š CodeGen (similar to StarCoder)
================================================================================

ğŸ“ˆ BASIC STATISTICS:
  â€¢ Total tokens: 84
  â€¢ Original text length: 134 characters
  â€¢ Compression ratio: 1.60 chars/token
  â€¢ Vocabulary size: 50,257

ğŸ”– SPECIAL TOKENS:
  â€¢ UNK: '<|endoftext|>' (ID: 50256)
  â€¢ BOS: '<|endoftext|>' (ID: 50256)
  â€¢ EOS: '<|endoftext|>' (ID: 50256)

ğŸ”§ TOKENIZATION STRATEGY:
  â€¢ Tokenizer class: CodeGenTokenizerFast
  â€¢ Strategy: Unknown/Custom
  â€¢ Model max length: 2048

ğŸ“Š TOKEN BREAKDOWN ANALYSIS:
  â€¢ Special tokens in output: 0
  â€¢ Unknown tokens [UNK]: 0
  â€¢ Subword tokens: 0
  â€¢ Regular tokens: 84

ğŸ” CONTENT-SPECIFIC HANDLING:
  â€¢ Capitalization: 4 tokens (avg 3.50 chars/token)
  â€¢ Python keywords: 4 tokens (avg 3.75 chars/token)
  â€¢ Operators: 2 tokens (avg 2.50 chars/token)
  â€¢ Numbers: 7 tokens (avg 1.57 chars/token)
  â€¢ Emojis: 11 tokens (avg 0.36 chars/token)
  â€¢ Non-English: 23 tokens (avg 0.70 chars/token)

ğŸ¨ VISUAL TOKENIZATION:
  [0;30;48;2;102;194;165mEnglish[0m [0;30;48;2;252;141;98mÂ·and[0m [0;30;48;2;141;160;203mÂ·CAP[0m [0;30;48;2;231;138;195mITAL[0m [0;30;48;2;166;216;84mIZ[0m [0;30;48;2;255;217;47mATION[0m [0;30;48;2;255;127;0m\n[0m [0;30;48;2;202;178;214mshow[0m [0;30;48;2;106;61;154m_[0m [0;30;48;2;102;194;165mt[0m [0;30;48;2;252;141;98mok[0m [0;30;48;2;141;160;203mens[0m [0;30;48;2;231;138;195mÂ·False[0m [0;30;48;2;166;216;84mÂ·None[0m [0;30;48;2;255;217;47mÂ·el[0m [0;30;48;2;255;127;0mif[0m [0;30;48;2;202;178;214mÂ·==[0m [0;30;48;2;106;61;154mÂ·>=[0m [0;30;48;2;102;194;165mÂ·else[0m [0;30;48;2;252;141;98m:[0m [0;30;48;2;141;160;203mÂ·two[0m [0;30;48;2;231;138;195mÂ·tabs[0m [0;30;48;2;166;216;84m:"[0m [0;30;48;2;255;217;47m\t\t[0m [0;30;48;2;255;127;0m"[0m [0;30;48;2;202;178;214mÂ·Three[0m [0;30;48;2;106;61;154mÂ·tabs[0m [0;30;48;2;102;194;165m:[0m [0;30;48;2;252;141;98m\t\t\t[0m [0;30;48;2;141;160;203m\n[0m [0;30;48;2;231;138;195m12[0m [0;30;48;2;166;216;84m.[0m [0;30;48;2;255;217;47m0[0m [0;30;48;2;255;127;0m*[0m [0;30;48;2;202;178;214m50[0m [0;30;48;2;106;61;154m=[0m [0;30;48;2;102;194;165m600[0m [0;30;48;2;252;141;98m\n[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¸[0m [0;30;48;2;255;127;0m\n[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mÙ†[0m [0;30;48;2;252;141;98mØ¯[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mä¸­[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mØ§Ù„[0m [0;30;48;2;106;61;154mØ¹[0m [0;30;48;2;102;194;165mØ±[0m [0;30;48;2;252;141;98mØ¨[0m [0;30;48;2;141;160;203mÙŠ[0m [0;30;48;2;231;138;195mØ©[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m 

ğŸ“ DETAILED TOKEN LIST (first 50 tokens):
  [ 0] ID: 15823 â†’ English
  [ 1] ID:   290 â†’  and
  [ 2] ID: 20176 â†’  CAP
  [ 3] ID: 40579 â†’ ITAL
  [ 4] ID: 14887 â†’ IZ
  [ 5] ID:  6234 â†’ ATION
  [ 6] ID:   198 â†’ \n
  [ 7] ID: 12860 â†’ show
  [ 8] ID:    62 â†’ _
  [ 9] ID:    83 â†’ t
  [10] ID:   482 â†’ ok
  [11] ID:   641 â†’ ens
  [12] ID: 10352 â†’  False
  [13] ID:  6045 â†’  None
  [14] ID:  1288 â†’  el
  [15] ID:   361 â†’ if
  [16] ID:  6624 â†’  ==
  [17] ID: 18189 â†’  >=
  [18] ID:  2073 â†’  else
  [19] ID:    25 â†’ :
  [20] ID:   734 â†’  two
  [21] ID: 22524 â†’  tabs
  [22] ID: 11097 â†’ :"
  [23] ID: 50294 â†’ \t\t
  [24] ID:     1 â†’ "
  [25] ID:  7683 â†’  Three
  [26] ID: 22524 â†’  tabs
  [27] ID:    25 â†’ :
  [28] ID: 50293 â†’ \t\t\t
  [29] ID:   198 â†’ \n
  [30] ID:  1065 â†’ 12
  [31] ID:    13 â†’ .
  [32] ID:    15 â†’ 0
  [33] ID:     9 â†’ *
  [34] ID:  1120 â†’ 50
  [35] ID:    28 â†’ =
  [36] ID:  8054 â†’ 600
  [37] ID:   198 â†’ \n
  [38] ID:  8582 â†’ ï¿½
  [39] ID:   104 â†’ ï¿½
  [40] ID:    94 â†’ ï¿½
  [41] ID: 41840 â†’ ï¿½
  [42] ID:   233 â†’ ï¿½
  [43] ID:  8582 â†’ ï¿½
  [44] ID:   237 â†’ ï¿½
  [45] ID:   122 â†’ ï¿½
  [46] ID:  8582 â†’ ï¿½
  [47] ID:    97 â†’ ï¿½
  [48] ID:   245 â†’ ï¿½
  [49] ID:  8582 â†’ ï¿½
  ... and 34 more tokens

================================================================================
ğŸ“Š Galactica
================================================================================

ğŸ“ˆ BASIC STATISTICS:
  â€¢ Total tokens: 101
  â€¢ Original text length: 134 characters
  â€¢ Compression ratio: 1.33 chars/token
  â€¢ Vocabulary size: 50,000

ğŸ”– SPECIAL TOKENS:

ğŸ”§ TOKENIZATION STRATEGY:
  â€¢ Tokenizer class: PreTrainedTokenizerFast
  â€¢ Strategy: Unknown/Custom
  â€¢ Model max length: 1000000000000000019884624838656

ğŸ“Š TOKEN BREAKDOWN ANALYSIS:
  â€¢ Special tokens in output: 0
  â€¢ Unknown tokens [UNK]: 0
  â€¢ Subword tokens: 0
  â€¢ Regular tokens: 101

ğŸ” CONTENT-SPECIFIC HANDLING:
  â€¢ Capitalization: 3 tokens (avg 4.67 chars/token)
  â€¢ Python keywords: 3 tokens (avg 5.00 chars/token)
  â€¢ Operators: 4 tokens (avg 1.25 chars/token)
  â€¢ Numbers: 11 tokens (avg 1.00 chars/token)
  â€¢ Emojis: 16 tokens (avg 0.25 chars/token)
  â€¢ Non-English: 24 tokens (avg 0.67 chars/token)

ğŸ¨ VISUAL TOKENIZATION:
  [0;30;48;2;102;194;165mEnglish[0m [0;30;48;2;252;141;98mÂ·and[0m [0;30;48;2;141;160;203mÂ·CAP[0m [0;30;48;2;231;138;195mITAL[0m [0;30;48;2;166;216;84mIZATION[0m [0;30;48;2;255;217;47m\n[0m [0;30;48;2;255;127;0mshow[0m [0;30;48;2;202;178;214m_[0m [0;30;48;2;106;61;154mtokens[0m [0;30;48;2;102;194;165mÂ·False[0m [0;30;48;2;252;141;98mÂ·None[0m [0;30;48;2;141;160;203mÂ·elif[0m [0;30;48;2;231;138;195mÂ·[0m [0;30;48;2;166;216;84m==[0m [0;30;48;2;255;217;47mÂ·[0m [0;30;48;2;255;127;0m>[0m [0;30;48;2;202;178;214m=[0m [0;30;48;2;106;61;154mÂ·else[0m [0;30;48;2;102;194;165m:[0m [0;30;48;2;252;141;98mÂ·two[0m [0;30;48;2;141;160;203mÂ·t[0m [0;30;48;2;231;138;195mabs[0m [0;30;48;2;166;216;84m:[0m [0;30;48;2;255;217;47m"[0m [0;30;48;2;255;127;0m\t\t[0m [0;30;48;2;202;178;214m"[0m [0;30;48;2;106;61;154mÂ·Three[0m [0;30;48;2;102;194;165mÂ·t[0m [0;30;48;2;252;141;98mabs[0m [0;30;48;2;141;160;203m:[0m [0;30;48;2;231;138;195m\t\t\t[0m [0;30;48;2;166;216;84m\n[0m [0;30;48;2;255;217;47m1[0m [0;30;48;2;255;127;0m2[0m [0;30;48;2;202;178;214m.[0m [0;30;48;2;106;61;154m0[0m [0;30;48;2;102;194;165m*[0m [0;30;48;2;252;141;98m5[0m [0;30;48;2;141;160;203m0[0m [0;30;48;2;231;138;195m=[0m [0;30;48;2;166;216;84m6[0m [0;30;48;2;255;217;47m0[0m [0;30;48;2;255;127;0m0[0m [0;30;48;2;202;178;214m\n[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84m\n[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mÙ†[0m [0;30;48;2;106;61;154mØ¯[0m [0;30;48;2;102;194;165mÛŒ[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mØ§Ù„[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mØ±[0m [0;30;48;2;102;194;165mØ¨[0m [0;30;48;2;252;141;98mÙŠ[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mí•œ[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m 

ğŸ“ DETAILED TOKEN LIST (first 50 tokens):
  [ 0] ID: 28003 â†’ English
  [ 1] ID:   312 â†’  and
  [ 2] ID: 18320 â†’  CAP
  [ 3] ID: 36247 â†’ ITAL
  [ 4] ID: 29196 â†’ IZATION
  [ 5] ID:   221 â†’ \n
  [ 6] ID: 14592 â†’ show
  [ 7] ID:    85 â†’ _
  [ 8] ID: 24948 â†’ tokens
  [ 9] ID: 12051 â†’  False
  [10] ID:  4830 â†’  None
  [11] ID: 14155 â†’  elif
  [12] ID:   243 â†’  
  [13] ID:  1414 â†’ ==
  [14] ID:   243 â†’  
  [15] ID:    52 â†’ >
  [16] ID:    51 â†’ =
  [17] ID:  3683 â†’  else
  [18] ID:    48 â†’ :
  [19] ID:   682 â†’  two
  [20] ID:   279 â†’  t
  [21] ID:  6510 â†’ abs
  [22] ID:    48 â†’ :
  [23] ID:    24 â†’ "
  [24] ID:  1211 â†’ \t\t
  [25] ID:    24 â†’ "
  [26] ID:  5753 â†’  Three
  [27] ID:   279 â†’  t
  [28] ID:  6510 â†’ abs
  [29] ID:    48 â†’ :
  [30] ID:  4388 â†’ \t\t\t
  [31] ID:   221 â†’ \n
  [32] ID:    39 â†’ 1
  [33] ID:    40 â†’ 2
  [34] ID:    36 â†’ .
  [35] ID:    38 â†’ 0
  [36] ID:    32 â†’ *
  [37] ID:    43 â†’ 5
  [38] ID:    38 â†’ 0
  [39] ID:    51 â†’ =
  [40] ID:    44 â†’ 6
  [41] ID:    38 â†’ 0
  [42] ID:    38 â†’ 0
  [43] ID:   221 â†’ \n
  [44] ID:   195 â†’ ï¿½
  [45] ID:   276 â†’ ï¿½
  [46] ID:   127 â†’ ï¿½
  [47] ID:   117 â†’ ï¿½
  [48] ID:   195 â†’ ï¿½
  [49] ID:   276 â†’ ï¿½
  ... and 51 more tokens

================================================================================
ğŸ“Š Phi-3 and Llama 2
================================================================================

ğŸ“ˆ BASIC STATISTICS:
  â€¢ Total tokens: 91
  â€¢ Original text length: 134 characters
  â€¢ Compression ratio: 1.47 chars/token
  â€¢ Vocabulary size: 32,000

ğŸ”– SPECIAL TOKENS:
  â€¢ PAD: '<|endoftext|>' (ID: 32000)
  â€¢ UNK: '<unk>' (ID: 0)
  â€¢ BOS: '<s>' (ID: 1)
  â€¢ EOS: '<|endoftext|>' (ID: 32000)

ğŸ”§ TOKENIZATION STRATEGY:
  â€¢ Tokenizer class: LlamaTokenizerFast
  â€¢ Strategy: SentencePiece (Unigram)
  â€¢ Model max length: 4096

ğŸ“Š TOKEN BREAKDOWN ANALYSIS:
  â€¢ Special tokens in output: 0
  â€¢ Unknown tokens [UNK]: 0
  â€¢ Subword tokens: 0
  â€¢ Regular tokens: 91

ğŸ” CONTENT-SPECIFIC HANDLING:
  â€¢ Capitalization: 6 tokens (avg 2.33 chars/token)
  â€¢ Python keywords: 3 tokens (avg 5.00 chars/token)
  â€¢ Operators: 2 tokens (avg 2.50 chars/token)
  â€¢ Numbers: 12 tokens (avg 0.92 chars/token)
  â€¢ Emojis: 17 tokens (avg 0.24 chars/token)
  â€¢ Non-English: 16 tokens (avg 1.00 chars/token)

ğŸ¨ VISUAL TOKENIZATION:
  [0;30;48;2;102;194;165mEnglish[0m [0;30;48;2;252;141;98mand[0m [0;30;48;2;141;160;203mC[0m [0;30;48;2;231;138;195mAP[0m [0;30;48;2;166;216;84mIT[0m [0;30;48;2;255;217;47mAL[0m [0;30;48;2;255;127;0mIZ[0m [0;30;48;2;202;178;214mATION[0m [0;30;48;2;106;61;154m\n[0m [0;30;48;2;102;194;165mshow[0m [0;30;48;2;252;141;98m_[0m [0;30;48;2;141;160;203mto[0m [0;30;48;2;231;138;195mkens[0m [0;30;48;2;166;216;84mFalse[0m [0;30;48;2;255;217;47mNone[0m [0;30;48;2;255;127;0melif[0m [0;30;48;2;202;178;214m==[0m [0;30;48;2;106;61;154m>=[0m [0;30;48;2;102;194;165melse[0m [0;30;48;2;252;141;98m:[0m [0;30;48;2;141;160;203mtwo[0m [0;30;48;2;231;138;195mtabs[0m [0;30;48;2;166;216;84m:"[0m [0;30;48;2;255;217;47m\t[0m [0;30;48;2;255;127;0m\t[0m [0;30;48;2;202;178;214m"[0m [0;30;48;2;106;61;154mThree[0m [0;30;48;2;102;194;165mtabs[0m [0;30;48;2;252;141;98m:[0m [0;30;48;2;141;160;203m\t[0m [0;30;48;2;231;138;195m\t[0m [0;30;48;2;166;216;84m\t[0m [0;30;48;2;255;217;47m\n[0m [0;30;48;2;255;127;0m1[0m [0;30;48;2;202;178;214m2[0m [0;30;48;2;106;61;154m.[0m [0;30;48;2;102;194;165m0[0m [0;30;48;2;252;141;98m*[0m [0;30;48;2;141;160;203m5[0m [0;30;48;2;231;138;195m0[0m [0;30;48;2;166;216;84m=[0m [0;30;48;2;255;217;47m6[0m [0;30;48;2;255;127;0m0[0m [0;30;48;2;202;178;214m0[0m [0;30;48;2;106;61;154m\n[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mï¿½[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¿½[0m [0;30;48;2;231;138;195mï¿½[0m [0;30;48;2;166;216;84mï¿½[0m [0;30;48;2;255;217;47mï¿½[0m [0;30;48;2;255;127;0mâ€[0m [0;30;48;2;202;178;214mï¿½[0m [0;30;48;2;106;61;154mï¿½[0m [0;30;48;2;102;194;165mï¿½[0m [0;30;48;2;252;141;98mï¿½[0m [0;30;48;2;141;160;203mï¸[0m [0;30;48;2;231;138;195m\n[0m [0;30;48;2;166;216;84mÛ[0m [0;30;48;2;255;217;47mÙ†[0m [0;30;48;2;255;127;0mØ¯[0m [0;30;48;2;202;178;214mÛŒ[0m [0;30;48;2;106;61;154mä¸­[0m [0;30;48;2;102;194;165mæ–‡[0m [0;30;48;2;252;141;98mØ§Ù„[0m [0;30;48;2;141;160;203mØ¹[0m [0;30;48;2;231;138;195mØ±[0m [0;30;48;2;166;216;84mØ¨[0m [0;30;48;2;255;217;47mÙŠ[0m [0;30;48;2;255;127;0mØ©[0m [0;30;48;2;202;178;214mí•œ[0m [0;30;48;2;106;61;154mêµ­[0m [0;30;48;2;102;194;165mì–´[0m 

ğŸ“ DETAILED TOKEN LIST (first 50 tokens):
  [ 0] ID:  4223 â†’ English
  [ 1] ID:   322 â†’ and
  [ 2] ID:   315 â†’ C
  [ 3] ID:  3301 â†’ AP
  [ 4] ID:  1806 â†’ IT
  [ 5] ID:  1964 â†’ AL
  [ 6] ID: 26664 â†’ IZ
  [ 7] ID:  8098 â†’ ATION
  [ 8] ID:    13 â†’ \n
  [ 9] ID:  4294 â†’ show
  [10] ID: 29918 â†’ _
  [11] ID:   517 â†’ to
  [12] ID: 12360 â†’ kens
  [13] ID:  7700 â†’ False
  [14] ID:  6213 â†’ None
  [15] ID: 25342 â†’ elif
  [16] ID:  1275 â†’ ==
  [17] ID:  6736 â†’ >=
  [18] ID:  1683 â†’ else
  [19] ID: 29901 â†’ :
  [20] ID:  1023 â†’ two
  [21] ID: 18859 â†’ tabs
  [22] ID:  6160 â†’ :"
  [23] ID:    12 â†’ \t
  [24] ID:    12 â†’ \t
  [25] ID: 29908 â†’ "
  [26] ID: 12753 â†’ Three
  [27] ID: 18859 â†’ tabs
  [28] ID: 29901 â†’ :
  [29] ID:    12 â†’ \t
  [30] ID:    12 â†’ \t
  [31] ID:    12 â†’ \t
  [32] ID:    13 â†’ \n
  [33] ID: 29896 â†’ 1
  [34] ID: 29906 â†’ 2
  [35] ID: 29889 â†’ .
  [36] ID: 29900 â†’ 0
  [37] ID: 29930 â†’ *
  [38] ID: 29945 â†’ 5
  [39] ID: 29900 â†’ 0
  [40] ID: 29922 â†’ =
  [41] ID: 29953 â†’ 6
  [42] ID: 29900 â†’ 0
  [43] ID: 29900 â†’ 0
  [44] ID:    13 â†’ \n
  [45] ID:   243 â†’ ï¿½
  [46] ID:   162 â†’ ï¿½
  [47] ID:   174 â†’ ï¿½
  [48] ID:   164 â†’ ï¿½
  [49] ID:   243 â†’ ï¿½
  ... and 41 more tokens


================================================================================
ğŸ“Š SUMMARY COMPARISON TABLE
================================================================================

Tokenizer                           Tokens     Vocab Size      Compression    
--------------------------------------------------------------------------------
BERT base model (uncased)           59         30,522          2.27           
BERT base model (cased)             53         28,996          2.53           
GPT-2                               87         50,257          1.54           
FLAN-T5                             49         32,100          2.73           
CodeGen (similar to StarCoder)      84         50,257          1.60           
Galactica                           101        50,000          1.33           
Phi-3 and Llama 2                   91         32,000          1.47           

================================================================================
